import streamlit as st
import google.generativeai as genai
import json
import time
import pandas as pd
from gtts import gTTS
from io import BytesIO

# --- 1. é é¢åŸºç¤è¨­å®š ---
st.set_page_config(page_title="AI è‹±æ–‡éš¨èº«æ•™ç·´", page_icon="ğŸ“")

st.title("ğŸ“ AI è‹±æ–‡éš¨èº«æ•™ç·´")
st.markdown("é€™æ˜¯ä¸€å€‹è®“ä½ å¯ä»¥ç”¨ã€Œä¸­è‹±å¤¾é›œã€ç·´ç¿’å£èªªçš„å·¥å…·ã€‚")

# --- 2. å´é‚Šæ¬„ï¼šAPI Key è¨­å®š ---
with st.sidebar:
    st.header("ğŸ”‘ è¨­å®š")
    user_api_key = st.text_input("è«‹è¼¸å…¥ Google Gemini API Key", type="password")
    st.markdown("[ğŸ‘‰ æŒ‰æ­¤å…è²»ç”³è«‹ API Key](https://aistudio.google.com/app/apikey)")
    st.divider()
    st.caption("ç”± [æ‚¨çš„åå­—] é–‹ç™¼è¨­è¨ˆ")

# --- 3. åˆå§‹åŒ– Session State (è¨˜æ†¶é«”) ---
if "mistakes" not in st.session_state:
    st.session_state.mistakes = []
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- 4. æ ¸å¿ƒå‡½å¼ï¼šå‘¼å« AI ---
def get_ai_response(text, api_key):
    genai.configure(api_key=api_key)
    try:
        # ä½¿ç”¨æ‚¨æŒ‡å®šçš„ Gemini 2.5 Flash æ¨¡å‹
        model = genai.GenerativeModel(
            model_name="models/gemini-2.5-flash", 
            generation_config={"response_mime_type": "application/json", "temperature": 0.7},
            system_instruction="""
            You are an enthusiastic English conversation coach.
            User speaks mixed Chinese/English.
            Output JSON:
            {
                "correction": "Correct English sentence",
                "explanation": "Explanation in Traditional Chinese",
                "reply": "Roleplay response in English",
                "reply_zh": "Chinese translation of reply"
            }
            """
        )
        response = model.generate_content(text)
        return json.loads(response.text)
    except Exception as e:
        return {"error": str(e)}

# --- 5. æ ¸å¿ƒå‡½å¼ï¼šæ–‡å­—è½‰èªéŸ³ (ä¸å­˜æª”ï¼Œç›´æ¥è½‰ Bytes) ---
def text_to_audio(text):
    if not text: return None
    try:
        tts = gTTS(text=text, lang='en')
        fp = BytesIO()
        tts.write_to_fp(fp)
        fp.seek(0)
        return fp
    except:
        return None

# --- 6. ä¸»ç•«é¢é‚è¼¯ ---

# å¦‚æœæ²’æœ‰ Keyï¼Œé–ä½ç•«é¢
if not user_api_key:
    st.warning("ğŸ‘ˆ è«‹å…ˆåœ¨å·¦å´æ¬„ä½è¼¸å…¥æ‚¨çš„ API Key æ‰èƒ½é–‹å§‹å–”ï¼")
else:
    # A. é¡¯ç¤ºæ­·å²è¨Šæ¯
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            # é¡¯ç¤ºæ–‡å­—
            if "display_text" in msg:
                st.markdown(msg["display_text"])
            else:
                st.write(msg["content"])
            
            # é¡¯ç¤ºæ­·å²èªéŸ³ (å¦‚æœæœ‰çš„è©±)
            if "audio_reply" in msg and msg["audio_reply"]:
                st.caption("ğŸ”Š è½ AI å›æ‡‰ (Reply):")
                st.audio(msg["audio_reply"], format='audio/mp3')
            
            if "audio_correction" in msg and msg["audio_correction"]:
                st.caption("ğŸ”Š è½æ­£ç¢ºèªªæ³• (Correction):")
                st.audio(msg["audio_correction"], format='audio/mp3')

    # B. è¼¸å…¥æ¡†è™•ç†
    if user_input := st.chat_input("è©¦è‘—èªªï¼šæˆ‘æƒ³è¦ book ä¸€å€‹ table..."):
        # 1. é¡¯ç¤ºä½¿ç”¨è€…è¼¸å…¥
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.write(user_input)

        # 2. å‘¼å« AI
        with st.spinner("AI æ­£åœ¨æ€è€ƒ..."):
            ai_data = get_ai_response(user_input, user_api_key)

        # 3. è™•ç†çµæœ
        if "error" in ai_data:
            st.error(f"ç™¼ç”ŸéŒ¯èª¤: {ai_data['error']} (è«‹æª¢æŸ¥ API Key æˆ–æ¨¡å‹åç¨±)")
        else:
            # è§£æ JSON
            reply_text = ai_data.get('reply', '')
            reply_zh = ai_data.get('reply_zh', '')
            correction = ai_data.get('correction', '')
            explanation = ai_data.get('explanation', '')
            
            # ç”Ÿæˆå…©å€‹èªéŸ³æª”
            audio_correction = text_to_audio(correction)
            audio_reply = text_to_audio(reply_text)
            
            # çµ„åˆé¡¯ç¤ºç”¨çš„æ–‡å­— Markdown
            display_text = f"""
            **ğŸ¤– å›æ‡‰:** {reply_text}
            *({reply_zh})*
            
            ---
            âœ¨ **ä¿®æ­£:** `{correction}`
            
            ğŸ’¡ **é»è©•:** {explanation}
            """

            # é¡¯ç¤º AI å›æ‡‰å€å¡Š
            with st.chat_message("assistant"):
                st.markdown(display_text)
                
                # æ’­æ”¾å™¨ 1: AI å›æ‡‰
                if audio_reply:
                    st.caption("ğŸ”Š è½ AI å›æ‡‰ (Reply):")
                    st.audio(audio_reply, format='audio/mp3')

                # æ’­æ”¾å™¨ 2: æ­£ç¢ºèªªæ³•
                if audio_correction:
                    st.caption("ğŸ”Š è½æ­£ç¢ºèªªæ³• (Correction):")
                    st.audio(audio_correction, format='audio/mp3')

            # 4. å­˜å…¥æ­·å²ç´€éŒ„ (åŒ…å«èªéŸ³ç‰©ä»¶)
            st.session_state.messages.append({
                "role": "assistant", 
                "content": reply_text,
                "display_text": display_text,
                "audio_reply": audio_reply,
                "audio_correction": audio_correction
            })

            # 5. è‡ªå‹•åŠ å…¥éŒ¯é¡Œæœ¬
            st.session_state.mistakes.append({
                "åŸå¥": user_input,
                "ä¿®æ­£": correction,
                "è§£æ": explanation,
                "AIå›æ‡‰": reply_text
            })

# --- 7. ä¸‹è¼‰æŒ‰éˆ•å€åŸŸ ---
if st.session_state.mistakes:
    st.divider()
    df = pd.DataFrame(st.session_state.mistakes)
    # è½‰æˆ CSV (åŠ ä¸Š BOM é˜²æ­¢ä¸­æ–‡äº‚ç¢¼)
    csv = df.to_csv(index=False).encode('utf-8-sig')
    
    st.download_button(
        label="ğŸ“¥ ä¸‹è¼‰æœ¬æ¬¡ç·´ç¿’ç­†è¨˜ (CSV)",
        data=csv,
        file_name='my_english_mistakes.csv',
        mime='text/csv',
    )
    
